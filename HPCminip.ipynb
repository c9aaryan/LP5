{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "AARYAN JOSHI <br>\n",
        "BACO19112 <br>\n",
        "BE - A <br>\n",
        "LP5 <br>\n",
        "HPC Mini Project - Mini Project: Implement Huffman Encoding on GPU"
      ],
      "metadata": {
        "id": "Gg3fGjNxlYhs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_YYHQsNjVR9",
        "outputId": "5412488c-e57e-4cc4-cc4c-399d3311c562"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3CrztpQjn58",
        "outputId": "d51e54c1-ffac-48e0-d419-ad574b2070ac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-1bekcz_f\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-1bekcz_f\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4287 sha256=344f683c4e68ede8d9f0be5350154c4a3798f4ff976229a86d4f8c0ef421dc5e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6uec3brh/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext Cython"
      ],
      "metadata": {
        "id": "aE0QyRvGjqs-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt update -qq;\n",
        "!wget https://developer.nvidia.com/compute/cuda/8.0/Prod2/local_installers/cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb;\n",
        "!dpkg -i cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb;\n",
        "!apt-key add /var/cuda-repo-8-0-local-ga2/7fa2af80.pub;\n",
        "!apt-get update -qq;\n",
        "!apt-get install cuda gcc-5 g++-5 -y -qq;\n",
        "!ln -s /usr/bin/gcc-5 /usr/local/cuda/bin/gcc;\n",
        "!ln -s /usr/bin/g++-5 /usr/local/cuda/bin/g++;\n",
        "!apt install cuda-8.0;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnTS23_5kksy",
        "outputId": "1f8e2e4e-9b9d-4dcf-c3ba-a71290c6a8d4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "--2023-05-16 21:59:37--  https://developer.nvidia.com/compute/cuda/8.0/Prod2/local_installers/cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb\n",
            "Resolving developer.nvidia.com (developer.nvidia.com)... 152.199.39.144\n",
            "Connecting to developer.nvidia.com (developer.nvidia.com)|152.199.39.144|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://developer.nvidia.com/downloads/compute/cuda/8.0/Prod2/local_installers/cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb [following]\n",
            "--2023-05-16 21:59:38--  https://developer.nvidia.com/downloads/compute/cuda/8.0/Prod2/local_installers/cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb\n",
            "Reusing existing connection to developer.nvidia.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://developer.download.nvidia.com/compute/cuda/8.0/secure/Prod2/local_installers/cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64.deb?1-zaVEfcWljZXUiMh2NBlgNg9GckxAKTb-N140avkBzwipG2WBon46j7FPXzall5wBFyGFkU1ItntN44_bE7-VPqYn-LPYWxT8SFdRsIe2LAw3w9sJDP-aK_xsMdETwVdcEbJR5KkE1ctOE3c0V4scGuEwSR9Skt-qFXYeWLOlbppq_cNm7Y_uAK8-N0xkNHFr9bntk_zeDSe7fw8yaNnhcJEg== [following]\n",
            "--2023-05-16 21:59:39--  https://developer.download.nvidia.com/compute/cuda/8.0/secure/Prod2/local_installers/cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64.deb?1-zaVEfcWljZXUiMh2NBlgNg9GckxAKTb-N140avkBzwipG2WBon46j7FPXzall5wBFyGFkU1ItntN44_bE7-VPqYn-LPYWxT8SFdRsIe2LAw3w9sJDP-aK_xsMdETwVdcEbJR5KkE1ctOE3c0V4scGuEwSR9Skt-qFXYeWLOlbppq_cNm7Y_uAK8-N0xkNHFr9bntk_zeDSe7fw8yaNnhcJEg==\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.199.39.144\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.199.39.144|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1913589814 (1.8G) [application/x-deb]\n",
            "Saving to: ‘cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb’\n",
            "\n",
            "cuda-repo-ubuntu160 100%[===================>]   1.78G   238MB/s    in 7.1s    \n",
            "\n",
            "2023-05-16 21:59:46 (257 MB/s) - ‘cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb’ saved [1913589814/1913589814]\n",
            "\n",
            "Selecting previously unselected package cuda-repo-ubuntu1604-8-0-local-ga2.\n",
            "(Reading database ... 122520 files and directories currently installed.)\n",
            "Preparing to unpack cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb ...\n",
            "Unpacking cuda-repo-ubuntu1604-8-0-local-ga2 (8.0.61-1) ...\n",
            "Setting up cuda-repo-ubuntu1604-8-0-local-ga2 (8.0.61-1) ...\n",
            "Warning: The postinst maintainerscript of the package cuda-repo-ubuntu1604-8-0-local-ga2\n",
            "Warning: seems to use apt-key (provided by apt) without depending on gnupg or gnupg2.\n",
            "Warning: This will BREAK in the future and should be fixed by the package maintainer(s).\n",
            "Note: Check first if apt-key functionality is needed at all - it probably isn't!\n",
            "Warning: apt-key should not be used in scripts (called from postinst maintainerscript of the package cuda-repo-ubuntu1604-8-0-local-ga2)\n",
            "OK\n",
            "OK\n",
            "E: Package 'gcc-5' has no installation candidate\n",
            "E: Package 'g++-5' has no installation candidate\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "\u001b[1;31mE: \u001b[0mUnable to locate package cuda-8.0\u001b[0m\n",
            "\u001b[1;31mE: \u001b[0mCouldn't find any package by glob 'cuda-8.0'\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ieWFXoNlNcu",
        "outputId": "b5c0d2a9-aa97-48a2-8e84-b9887ccffe04"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void helloWorld() {\n",
        "    printf(\"Hello, World from GPU!\\n\");\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Launch CUDA kernel\n",
        "    helloWorld<<<1, 1>>>();\n",
        "\n",
        "    // Synchronize GPU threads\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-CSVAg6lN_Z",
        "outputId": "1422d230-6b58-4c5f-e826-ef657bb1c824"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, World from GPU!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "\n",
        "// Node structure for Huffman Tree\n",
        "struct Node {\n",
        "    char symbol;\n",
        "    int frequency;\n",
        "    Node* left;\n",
        "    Node* right;\n",
        "};\n",
        "\n",
        "// Kernel function for Huffman encoding on GPU\n",
        "__global__ void huffmanEncoding(char* input, int* output, int inputSize, Node* huffmanTree) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (tid < inputSize) {\n",
        "        char symbol = input[tid];\n",
        "        Node* currentNode = huffmanTree;\n",
        "\n",
        "        // Traverse the Huffman Tree until leaf node is reached\n",
        "        while (currentNode->left != NULL && currentNode->right != NULL) {\n",
        "            if (symbol == currentNode->left->symbol) {\n",
        "                output[tid] = 0;\n",
        "                currentNode = currentNode->left;\n",
        "            } else if (symbol == currentNode->right->symbol) {\n",
        "                output[tid] = 1;\n",
        "                currentNode = currentNode->right;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Initialize input data\n",
        "    char input[] = \"HELLO CUDA\";\n",
        "    int inputSize = sizeof(input) - 1;\n",
        "\n",
        "    // Create Huffman Tree\n",
        "    Node node1 = { 'D', 1, NULL, NULL };\n",
        "    Node node2 = { 'E', 1, NULL, NULL };\n",
        "    Node node3 = { 'H', 1, NULL, NULL };\n",
        "    Node node4 = { 'L', 2, NULL, NULL };\n",
        "    Node node5 = { 'O', 1, NULL, NULL };\n",
        "    Node node6 = { 'C', 1, &node1, &node2 };\n",
        "    Node node7 = { 'U', 1, &node3, &node4 };\n",
        "    Node node8 = { 'T', 1, &node5, &node6 };\n",
        "    Node huffmanTree = { '\\0', 0, &node7, &node8 };\n",
        "\n",
        "    // Allocate memory on GPU\n",
        "    char* d_input;\n",
        "    int* d_output;\n",
        "    Node* d_huffmanTree;\n",
        "    cudaMalloc((void**)&d_input, sizeof(char) * inputSize);\n",
        "    cudaMalloc((void**)&d_output, sizeof(int) * inputSize);\n",
        "    cudaMalloc((void**)&d_huffmanTree, sizeof(Node));\n",
        "\n",
        "    // Copy input data and Huffman Tree to GPU\n",
        "    cudaMemcpy(d_input, input, sizeof(char) * inputSize, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_huffmanTree, &huffmanTree, sizeof(Node), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define CUDA grid and block dimensions\n",
        "    int blockSize = 256;\n",
        "    int gridSize = (inputSize + blockSize - 1) / blockSize;\n",
        "\n",
        "    // Launch CUDA kernel for Huffman encoding\n",
        "    huffmanEncoding<<<gridSize, blockSize>>>(d_input, d_output, inputSize, d_huffmanTree);\n",
        "\n",
        "    // Copy the encoded output back to the CPU\n",
        "    int* encodedOutput = (int*)malloc(sizeof(int) * inputSize);\n",
        "    cudaMemcpy(encodedOutput, d_output, sizeof(int) * inputSize, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print the encoded output\n",
        "    printf(\"Input: %s\\n\", input);\n",
        "    printf(\"Encoded Output: \");\n",
        "    for (int i = 0; i < inputSize; i++) {\n",
        "        printf(\"%d\", encodedOutput[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    // Cleanup\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output);\n",
        "    cudaFree(d_huffmanTree);\n",
        "    free(encodedOutput);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FlupnislShK",
        "outputId": "b14f470e-736e-42cc-f267-ddb96d265fa0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: HELLO CUDA\n",
            "Encoded Output: 00001348955753176850953918673961762595660255996022084\n",
            "\n"
          ]
        }
      ]
    }
  ]
}